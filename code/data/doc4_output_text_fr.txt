Exploration du SVM-KNN avec des problèmes de vision  Joon Hyuck Choi (jchoilOO, jchoi100@jhu.edu) Joo Chang Lee (jlee381, jlee381@jhu.edu)  20 novembre 2016  1 Résumé  L&#39;algorithme k-Nearest Neighbor (KNN) est une méthode non paramétrique utilisée pour la classification et régression. Dans une précédente tâche, nous avons mis en œuvre le classificateur KNN standard Et une de ses variantes, la distance pondérée KNN. Nous avons ressenti le besoin de Cette affectation et d&#39;explorer un autre type de l&#39;algorithme KNN, qui est un peu plus impliqué.  Le KNN variante que nous explorons dans ce travail est le SVM-KNN, un algorithme KNN qui rend L&#39;utilisation d&#39;un SVM multiclasse du noyau comme sous-procédure. L&#39;approche du voisin le plus proche en Les problèmes de reconnaissance ont fait leurs preuves dans le passé [1]. Toutefois, malgré ses avantages, Car l&#39;approche NN peut souffrir d&#39;une forte variation due à l&#39;échantillonnage fini. L&#39;incorporation D&#39;une SVM peut remédier à cette situation.  Notons que les deux cas extrêmes du SVM-KNN sont les suivants:E KNN standard pour de petites valeurs K Et le SV&#39;M régulier pour K = n: L&#39;algorithme tente d&#39;abord de classifier les multiclasses en utilisant la Standard KNN avec un système de vote unanime. Lorsque au moins un vote est différent, il Le noyau mutliclass SVM pour la prédiction. &#39;  L&#39;utilisation d&#39;un SVM peut être efficace au voisinage d&#39;un petit nombre d&#39;exemples et d&#39;un petit Nombre de classes [1]. Nous visons à tester cet algorithme sur deux ensembles de données: MNIST [3] and USPS [4]. Les objectifs étendus incluent le test de l&#39;algorithme sur l&#39;ensemble de données Caltech 101 [5], qui Se compose d&#39;images du monde réel plus sophistiquées avec plus d&#39;étiquettes.  2 Méthodes  Commençons d&#39;abord notre propre norme KNN avec un vote unanime. En cas de désaccord, utilisez le noyau SVM de scikitlearn avec notre propre métrique de distance comme entrée. Implémentez le noyau Truc fourni dans [1] si nécessaire:  1 1 (X, y) = &lt;2:, y&gt; = § (&lt;1: 1:&gt; + &lt;i, y&gt; ) + D (y, 0) -d (.r, y))