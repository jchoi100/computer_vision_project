探索具有视觉问题的SVM-KNN  Joon Hyuck Choi（jchoilOO，jchoi100@jhu.edu） Joo Chang Lee（jlee381，jlee381@jhu.edu）  2016年11月20日  摘要  k-最近邻（KNN）算法是用于分类的非参数方法 回归。在以前的作业分配中，我们实现了标准的KNN分类器 和其变体之一，距离加权KNN。我们觉得需要采取另一个步骤 这种分配和探索另一种类型的KNN算法，这是一个更多的参与。  我们在这项工作中探索的KNN变体是SVM-KNN，一种KNN算法 使用内核多类SVM作为子过程。视觉中最近邻的方法 已经证明识别问题在过去很好[1]。然而，尽管它的好处， 导致NN方法可能遭受由于有限采样的高变化。合并 的SVM可以弥补这种情况。  注意，SVM-KNN的两种极端情况是the小K值的标准KNN 和K = n的常规SV&#39;M：算法首先尝试使用多类分类 标准KNN与一致投票方案。当至少一个投票不同时，它转向 核心多变SVM用于预测。 &#39;&#39;  使用SVM可以在邻域中有少量的示例和小的 类数[1]。我们的目标是测试这个算法对两个数据集：MNIST [3]和 USPS [4]。扩展目标包括测试Caltech 101 [5]数据集上的算法 包括更复杂的现实世界图像与更多的标签。  2方法  首先运行我们自己的标准KNN一致投票。在不一致的情况下，使用内核 SVM从我们自己的距离度量作为输入的scikitlearn。实现在我们自己的内核上 技巧在[1]中提供：  11 K（x，y）= &lt;2：，y&gt; =§（&lt;1：1：&gt; + &lt;i，y&gt;  -  &lt;：c -y，：c- ）+ d（y，0）-d（.r，y））