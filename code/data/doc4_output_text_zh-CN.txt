探索具有视觉问题的SVM-KNN  Joon Hyuck Choi（jchoilOO，jchoi100@jhu.edu） Joo Chang Lee（jlee381，jlee381@jhu.edu）  2016年11月20日  摘要  k-最近邻（KNN）算法是用于分类的非参数方法 回归。在以前的作业分配中，我们实现了标准的KNN分类器 和其变体之一，距离加权KNN。我们觉得需要采取另一个步骤 这种分配和探索另一种类型的KNN算法，这是一个更多的参与。  我们在这项工作中探索的KNN变量是SVM-KNN，一个&#39;KNN算法 使用内核多类SVM作为子过程。视觉中最近邻的方法 已经证明识别问题在过去很好[1]。然而，尽管它的好处， 导致NN方法可能遭受由于有限采样的高变化。合并 。的SVM可以弥补这种情况。 V  注意，SVM-KNN的两种极端情况 是小K值的标准KNN 和用于K n的常规SVM。该算法首先尝试使用的多类分类 标准KNN与一致投票方案。当至少一个投票不同时，它转向 核心多项式SVM&#39;用于预测。 *&#39;  使用SVM可以在小范围的实例和小的附近有效 类的数目[1]我们的目标是测试这个算法对两个数据集：MNIST [3]和 USPS [4]扩展目标包括测试Caltech 101 [5]数据集上的算法 包括更复杂的现实世界图像与更多的标签  &#39;2方法  首先运行我们自己的标准KNN一致投票。 “如果不同意，使用内核 SVM从我们自己的距离度量作为输入的scikitlearn。实现在我们自己的内核上 技巧在[l]中提供：  1，I&#39;1，&#39;， K（rc.y）= &lt;any&gt; =§（&lt;x&#39;x&gt; 1+ &lt;1M！&gt;  -  &lt;r6-11.x-&gt;&gt; = 5（d（x，0）+ d ），-d（x，y））