비전 문제로 SVM-KNN 탐색  최준혁 (jchoilOO, jchoi100@jhu.edu) 이주창 (jlee381, jlee381@jhu.edu)  2016 년 11 월 20 일  1 초록  k-Nearest Neighbor (KNN) 알고리즘은 분류에 사용되는 비모수 적 방법이며, 회귀. 이전 숙제에서는 표준 KNN 분류자를 구현했습니다. 및 그 변형 중 하나 인 거리 가중 KNN. 우리는 한 걸음 더 나아갈 필요성을 느꼈다. 이 과제를 수행하고 KNN 알고리즘의 다른 유형을 탐색합니다.이 알고리즘은 좀 더 복잡합니다.  이 작업에서 탐구 한 KNN 변종은 SVM-KNN입니다. 커널 다중 클래스 SVM을 하위 프로 시저로 사용. 시각적으로 가장 가까운 이웃 접근법 인식 문제는 과거에 잘 작동하는 것으로 입증되었습니다 [1]. 그러나 장점에도 불구하고, NN 접근법은 유한 샘플링으로 인해 높은 편차를 겪을 수 있습니다. 법인화 . SVM의이 문제를 해결할 수 있습니다. V  SVM-KNN의 두 극단적 인 경우 작은 K 값에 대한 표준 KNN입니다. K-n에 대한 정규 SVM. 알고리즘은 먼저 다중 클래스 분류를 시도한다. 만장일치 투표 방식의 표준 KNN. 적어도 하나의 투표가 다른 경우, 그것은로 바뀝니다. 예측을위한 커널 mutliclass SVM &#39;. * &#39;  SVM을 사용하면 작은 수의 예제와 작은 수의 이웃에서 효과적 일 수 있습니다. 클래스 수 [1]이 알고리즘을 두 개의 데이터 세트, 즉 MNIST [3]와 USPS [4] 확장 된 목표는 Caltech 101 [5] 데이터 세트에서 알고리즘을 테스트하는 것을 포함합니다. 더 많은 레이블이 포함 된보다 세련된 실제 이미지로 구성됩니다.  2 가지 방법  우선 우리 만의 표준 KNN을 만장일치로 투표하십시오. &#39;의견이 맞지 않으면 커널을 사용하십시오. SCM은 우리 자신의 거리 메트릭을 입력으로 사용합니다. 우리 자신의 커널을 구현하십시오. 필요에 따라 [l]에서 제공된 트릭 :  1., 나는 1, &#39;, = 0 (d (x, 0) + d (y, 0)) - K (rc.y) = &lt;any&gt; = § &lt;x&#39;x&gt; ), - d (x, y))