Erforschung des SVM-KNN mit Sehproblemen  Joon Hyuck Choi (jchoilOO, jchoi100@jhu.edu) Joo Chang Lee (jlee381, jlee381@jhu.edu)  20. November 2016  1 Zusammenfassung  Der k-Nearest Neighbor (KNN) -Algorithmus ist ein nicht-parametrisches Verfahren für die Klassifikation und Regression. In einer früheren Hausaufgabe implementierten wir den klassischen KNN-Klassifikator Und eine ihrer Varianten, die Distanz gewichtete KNN. Wir brauchten einen weiteren Schritt Diese Zuweisung und erkunden einen anderen Typ des KNN-Algorithmus, der ein wenig mehr beteiligt ist.  Die KNN-Variante, die wir in dieser Arbeit erforschen, ist der SVN-KNN, ein KNN-Algorithmus, der macht Verwendung eines Kernel-Multiclass-SVM als Unterprozedur. Der nächste Nachbarn Ansatz in Visual Erkennungsprobleme haben sich in der Vergangenheit bewährt [1]. Doch trotz seiner Vorteile, Weil der NN-Ansatz aufgrund einer feinen Probenentnahme eine hohe Variation aufweisen kann. Der Einbau Eines SVM kann diese Situation beheben.  Beachten Sie, dass die beiden Extremfälle des SVM-KNN th sindE Standard KNN für kleine K-Werte Und dem regulären SV&#39;M für K = n: Der Algorithmus versucht zunächst, die Klassifizierung von Multiclass unter Verwendung der Standard-KNN mit einem einstimmigen Wahlschema. Wenn mindestens eine Stimme anders ist, wendet sie sich an Das kernel mutliclass SVM für die Vorhersage. &#39;  Die Verwendung eines SVM kann in der Nachbarschaft einer kleinen Anzahl von Beispielen und einer kleinen wirksam sein Anzahl der Klassen [1]. Wir wollen diesen Algorithmus auf zwei Datensätzen testen: MNIST [3] und USPS [4]. Erweiterte Ziele umfassen das Testen des Algorithmus auf dem Caltech 101 [5] -Datensatz, der Besteht aus anspruchsvolleren Bildern der realen Welt mit mehr Labels.  2 Methoden  Zuerst laufen unsere eigenen Standard KNN mit einstimmiger Abstimmung. Im Falle von Meinungsverschiedenheiten, verwenden Sie den Kernel SVM von scikitlearn mit eigenem Abstand Metrik als Eingabe. Implementieren Sie auf unserem eigenen Kernel Trick in [1] wie nötig:  1 1 K (x, y) = &amp; lt; 2:, y &amp; gt; = § (&amp; lt; 1: 1: &amp; gt; ) + D (y, 0) -d (.r, y))